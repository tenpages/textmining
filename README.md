## Text-Mining Project: emoji Prediction of Tweets
by  **Jiarong Yu**, **Shuai Hao** and **Shuo Liu**

Dept. of Computer Science, Georgetown Univ.

Text Mining & Analysis (COSC-586), Fall 2017

### Division of work:
* **Jiarong Yu** and **Shuai Hao**: feature extraction and implementation. See folders **[pre_and_chi](https://github.com/tenpages/textmining/tree/master/pre_and_chi)** and **[features](https://github.com/tenpages/textmining/tree/master/features)** for detailed information;
* **Shuo Liu**: feature extraction (part of), baseline implementation, model training and evaluation. Also organized the reporsitory and the writing of final report.

### Code intro. & File structure:
├ **Data**

│  ├ tokenized trining & trial set ( *.tknz, delimiter=" " )

│  └ corresponding labels of each tweets ( *.label )

├ **evaluation**

│  ├ **models**

│  │  └ some of trained models saved for future checking out

│  ├ *evaluation.py*: code for generating reports on models by Shuo Liu

│  ├ results of different models ( *.labels )

│  └ reports on different methods ( *.txt )

├ **pre_and_chi**

│  ├ README.md

│  └ work done by Jiarong Yu: Part of preprocessing and part of feature extraction

├ **skip_gram**

│  ├ original text of tweets ( *.text* file ) and skip_gram model we used ( *.w2v* file )

│  └ *.py* files: used for tokenize and vectorize tweets from original texts by Shuo Liu

├ **features**

│  ├ topwords on each label with different methods of measure in folders **chi**, **chiwordnet**, **tf**, **tfidf**, etc., with filenames *topwords??.txt* ( ?? are no. of labels ). Generated by Jiarong yu ( *chi*s ) and Shuai Hao ( *tf* and *tfidf* )

│  ├ **vectors**: vectorized topword features

│  ├ *topwords.py*: code for vectorizing tweets with topword information by Shuo Liu

│  └ *bow.py*: code for bag-of-word baseline using tf/tfidf for dimensionality reduction by Shuo Liu

├ **training**: code for model training by Shuo Liu

└ **final_report**: our final report on this project
